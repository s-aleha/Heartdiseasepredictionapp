import pandas as pd
import numpy as np
import os
import joblib

from sklearn.pipeline import Pipeline
from sklearn.compose import ColumnTransformer
from sklearn.preprocessing import StandardScaler, OneHotEncoder

from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import SVC
from sklearn.cluster import KMeans




df = pd.read_csv("/kaggle/input/heart-disease-dataset/heart.csv")

FEATURE_COLUMNS = [
    "age", "sex", "cp", "trestbps", "chol",
    "fbs", "restecg", "thalach", "exang",
    "oldpeak", "slope", "ca", "thal"
]

TARGET_COLUMN = "target"

X = df[FEATURE_COLUMNS]
y = df[TARGET_COLUMN]





categorical_features = [
    "sex", "cp", "fbs", "restecg",
    "exang", "slope", "ca", "thal"
]

numerical_features = [
    col for col in FEATURE_COLUMNS if col not in categorical_features
]

preprocessor = ColumnTransformer(
    transformers=[
        ("num", StandardScaler(), numerical_features),
        ("cat", OneHotEncoder(handle_unknown="ignore", sparse_output=False), categorical_features)
    ]
)





logreg_pipeline = Pipeline(
    steps=[
        ("preprocessor", preprocessor),
        ("classifier", LogisticRegression(max_iter=1000))
    ]
)

logreg_pipeline.fit(X, y)

os.makedirs("/kaggle/working/models", exist_ok=True)
joblib.dump(
    logreg_pipeline,
    "/kaggle/working/models/logistic_regression.joblib",
    protocol=5
)

print("Logistic Regression saved")





rf_pipeline = Pipeline(
    steps=[
        ("preprocessor", preprocessor),
        ("classifier", RandomForestClassifier(
            n_estimators=200,
            random_state=42
        ))
    ]
)

rf_pipeline.fit(X, y)

joblib.dump(
    rf_pipeline,
    "/kaggle/working/models/random_forest.joblib",
    protocol=5
)

print("Random Forest saved")






svm_pipeline = Pipeline(
    steps=[
        ("preprocessor", preprocessor),
        ("classifier", SVC(
            kernel="rbf",
            probability=True,
            random_state=42
        ))
    ]
)

svm_pipeline.fit(X, y)

joblib.dump(
    svm_pipeline,
    "/kaggle/working/models/svm.joblib",
    protocol=5
)

print("SVM saved")








# Preprocess separately for KMeans
X_processed = preprocessor.fit_transform(X)

kmeans = KMeans(
    n_clusters=2,
    random_state=42,
    n_init=10
)

clusters = kmeans.fit_predict(X_processed)

# Map clusters to heart disease risk
cluster_risk = {
    int(cluster): float(y[clusters == cluster].mean())
    for cluster in np.unique(clusters)
}

kmeans_bundle = {
    "preprocessor": preprocessor,
    "kmeans": kmeans,
    "cluster_risk": cluster_risk
}

joblib.dump(
    kmeans_bundle,
    "/kaggle/working/models/kmeans.joblib",
    protocol=5
)

print("KMeans saved")
print("Cluster risk mapping:", cluster_risk)



os.listdir("/kaggle/working/models")
